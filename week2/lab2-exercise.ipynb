{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28af6193",
   "metadata": {},
   "source": [
    "# **Lab 2: Regression**\n",
    "\n",
    "In this lab session, we are given a dataset stored in 'regression-data.txt'. We will develop K Nearest Neighbors (KNNs), linear regression and polynomial regression to fit this dataset. \n",
    "\n",
    "**!!! IMPORTANT !!!**\n",
    "* Please turn OFF any code assistant such as CoPilot;\n",
    "* You MUST implement KNN, linear regression, and polynomial regression from scratch using the imported libraries below. No additional library is allowed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ad0295",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "325eddf0",
   "metadata": {},
   "source": [
    "### **Load the dataset**\n",
    "This dataset contains $200$ data points. Each row in the dataset is a data point of the form $[1,~x_1,~x_2,~y]$, where $x_1$ and $x_2$ are two features and $y$ is the target value (i.e., desired output). The first $100$ row will be the training data, next $50$ rows will be the validation data, and the last $50$ rows will be the test data.\n",
    "\n",
    "Represent the training data as numpy arrays ```Xtrain``` and ```Ytrain```, validation data as ```Xval``` and ```Yval```, and test data as ```Xtest``` and ```Ytest```. The shape of these numpy arrays are \n",
    "* ```Xtrain```: (100, 3)\n",
    "* ```Ytrain```: (100,) not (100, 1)\n",
    "* ```Xval```: (50, 3)\n",
    "* ```Yval```: (50,) not (50, 1)\n",
    "* ```Xtest```: (50, 3)\n",
    "* ```Ytest```: (50,) not (50, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "429ec17e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(filepath):\n",
    "    Xtrain, Ytrain, Xval, Yval, Xtest, Ytest = [], [], [], [], [], []\n",
    "    \n",
    "    # extract data from filepath\n",
    "    with open(filepath, 'r') as file:\n",
    "    \"\"\"\n",
    "    YOUR CODE HERE\n",
    "    \"\"\"\n",
    "    \n",
    "    Xtrain, Ytrain = np.array(Xtrain), np.array(Ytrain)\n",
    "    Xval, Yval = np.array(Xval), np.array(Yval)\n",
    "    Xtest, Ytest = np.array(Xtest), np.array(Ytest)\n",
    "    return Xtrain, Ytrain, Xval, Yval, Xtest, Ytest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f171d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = \"regression-data.txt\"\n",
    "Xtrain, Ytrain, Xval, Yval, Xtest, Ytest = read_data(filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d036be2",
   "metadata": {},
   "source": [
    "### **Implement K Nearest Neighbors**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "951e2693",
   "metadata": {},
   "source": [
    "Let's start with implementing a helper function ```euclidean_distance(Xtrain, Xtest)```. It will compute the Euclidean distance between each test point and all training points and save it into an numpy array ```distances``` of shape (100, 50)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "607d9a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_distance(Xtrain, Xtest):\n",
    "    \"\"\"\n",
    "    YOUR CODE HERE\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c1863dd",
   "metadata": {},
   "source": [
    "Now follow the instructions to implement your KNN regressor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d6c4e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn(Xtrain, Ytrain, Xtest, k):\n",
    "    # compute Euclidean distances between training data and test data\n",
    "    distances = euclidean_distance(Xtrain, Xtest)\n",
    "\n",
    "    # Get the indices of the k nearest neighbors\n",
    "    knn_indices = []\n",
    "    \"\"\"\n",
    "    YOUR CODE HERE\n",
    "    \"\"\"\n",
    "\n",
    "    # Get the labels of the k nearest neighbors\n",
    "    knn_labels = Ytrain[knn_indices]\n",
    "\n",
    "    # Return the weighted average among the k neighbors\n",
    "    # weights should be the reciprocal of the distance\n",
    "    \"\"\"\n",
    "    YOUR CODE HERE\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77b50fc4",
   "metadata": {},
   "source": [
    "Once we get the predictions, we calculate the mean squared error between predictions and ```Ytest```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "101b6bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get predictions\n",
    "predictions = knn(Xtrain, Ytrain, Xtest, 5)\n",
    "\n",
    "# helper function to calculate mean squared error\n",
    "def mean_squared_error(y_true, y_pred):\n",
    "    return np.mean((y_true - y_pred) ** 2)\n",
    "\n",
    "# calculate mean squared error\n",
    "print(\"Mean Squared Error:\", mean_squared_error(Ytest, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d24a0e94",
   "metadata": {},
   "source": [
    "However, it is hard to know the value of ```k``` that could achieve smallest mean squared error on test data. Thus, we will apply the so-called **elbow method** to find the optimal value ```k```.\n",
    "\n",
    "The elbow method runs like this:\n",
    "1. Iterate over a list of ```k``` values;\n",
    "2. For each ```k```, calculate the error (i.e., mean squared error in our case);\n",
    "3. Find ```k``` such that increasing or decreasing it will cause the error (e.g., mean squared error) to increase\n",
    "\n",
    "when you draw a curve of ```k``` vs. cost, you will find that the curve actually looks like an elbow -- that's why it is called the **elbow** method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bfa25d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "k_values = [1, 3, 5, 7, 9]\n",
    "costs = []\n",
    "\n",
    "# Now iterate your knn over the k_values and save the mean squared errors into costs\n",
    "\"\"\"\n",
    "YOUR CODE HERE\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "335f4828",
   "metadata": {},
   "source": [
    "We will draw a line of ```k``` vs. costs to help us visualize the change in costs and determine the best ```k``` value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d0402a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_costs_vs_k(k_values, costs):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(k_values, costs, marker='o')\n",
    "    plt.title('Mean Squared Error vs. k')\n",
    "    plt.xlabel('Number of Neighbors (k)')\n",
    "    plt.ylabel('Mean Squared Error')\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "draw_costs_vs_k(k_values, costs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa948516",
   "metadata": {},
   "source": [
    "***QUESTION***: From the figure drawn by running the code above, could you (1) identify what the best ```k``` value is? If yes, what is the value of ```k``` with the lowest cost? Write your answers in the Markdown cell below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49d7971f",
   "metadata": {},
   "source": [
    "***Answer:*** YOUR ANSWER HERE "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f2f252",
   "metadata": {},
   "source": [
    "### **Implement linear regression**\n",
    "\n",
    "Now we change our regressor from KNN to linear regression. Follow the instructions below to implement linear regression.\n",
    "\n",
    "$f(x) = w^T x$\n",
    "\n",
    "where $w[0]$ is the weight for the first column in our dataset $x[0] = 1$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b9a47e",
   "metadata": {},
   "source": [
    "Linear regression that optimizes the sum-of-square error has a closed-form solution of the optimal $w$, known as the normal equation. Now calculate the optimal weight w using normal equation and (```Xtrain```, ```Ytrain```)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9328ca73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normal_equation(Xtrain, Ytrain):\n",
    "    \"\"\"\n",
    "    YOUR CODE HERE\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f82fe6e",
   "metadata": {},
   "source": [
    "Once we have the optimal weight, we can use it make predictions on ```Xtest``` and calculate its mean squared error compared to ```Ytest```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f30575",
   "metadata": {},
   "outputs": [],
   "source": [
    "w_best = normal_equation(Xtrain, Ytrain)\n",
    "print(\"Mean Squared Error:\", mean_squared_error(Ytest, Xtest.dot(w_best)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a48a795",
   "metadata": {},
   "source": [
    "***Your submission will be graded based on the mean squared error you got by running the code above.***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5587580f",
   "metadata": {},
   "source": [
    "### **Implement polynomial regression**\n",
    "\n",
    "Sometimes we need a higher order model to more accuratelyâ€€fit the data. To implement polynomial regression, we will first implement a function ```polynomial_feature_transformation``` which takes ```Xtrain``` as input and transforms it into ```XtrainPoly```. Specifically, for our data with features $$[1, x_1, x_2],$$ we will transform it to $$[1, x_1, x_2, x_1 x_2, x_1^2, x_2^2].$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d548f9ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def polynomial_features(X):\n",
    "    \"\"\"\n",
    "    YOUR CODE HERE\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36b48723",
   "metadata": {},
   "source": [
    "Similarly, once we have the transformed features ```XtrainPoly```, we will use normal equation to compute the optimal weight ```w_best``` and report the mean squared error on test data (```Xtest```, ```Ytest```)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c20acec",
   "metadata": {},
   "outputs": [],
   "source": [
    "XtrainPoly = polynomial_features(Xtrain)\n",
    "w_best = normal_equation(XtrainPoly, Ytrain)\n",
    "XtestPoly = polynomial_features(Xtest)\n",
    "print(\"Mean Squared Error:\", mean_squared_error(Ytest, XtestPoly.dot(w_best)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e867fc67",
   "metadata": {},
   "source": [
    "***Your submission will be graded based on the mean squared error you got by running the code above.***"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
